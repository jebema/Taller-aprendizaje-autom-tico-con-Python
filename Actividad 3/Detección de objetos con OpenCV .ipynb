{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección de objetos usando openCV\n",
    "Curso: Aplicaciones del aprendizaje automático con Python <br>\n",
    "Actividad 3: Detección de objetos con OpenCV <br> <br>\n",
    "\n",
    "Aqui vamos a probar una función integrada en openCV que sirve para detectar objetos. En este ejercicio detectaremos caras y ojos.\n",
    "\n",
    "Objetivos:\n",
    "1. Usar un modelo previamente entrenado para detectar rostros y ojos (función CascadeClassifier de openCV)\n",
    "\n",
    "\n",
    "Dra. Jessica Beltrán Márquez <br>\n",
    "www.jessicabeltran.com.mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener la imagen\n",
    "Importamos las bibliotecas que vamos a utilizar.  \n",
    "Leemos los modelos de clasificación para *rostros frontales* y para *ojos*. Estos modelos contienen valores numéricos que ya estan entrenados. <br>\n",
    "Obtenemos la imagen a la cual le detectaremos los rostros y los ojos. <br>\n",
    "Convertimos la imagen a grises ya que asi la requiere el clasificador.<br>\n",
    "Desplegamos la imagen original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Se cargan los modelos para detectar rostros y ojos. NOTA: Estos modelos ya fueron entrenados previamente, solo los estamos usando\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') #Revisa que este archivo está en tu carpeta\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml') #Revisa que este archivo está en tu carpeta\n",
    "\n",
    "#Se lee la imagen\n",
    "img = cv2.imread('./images/twofaces1.jpg')\n",
    "\n",
    "#Se convierte a escala de grises\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "imgToShow =  img[:,:,::-1] \n",
    "\n",
    "#Se muestra la imagen\n",
    "plt.imshow(imgToShow)     \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos el modelo de clasificador *face_cascade* para detectar el rostro pasandole como parametro la imagen en grises.\n",
    "\n",
    "Esta función nos regresa las coordenadas para formar rectángulos en donde se incluyan rostros.\n",
    "Por cada rostro, se dibuja un rectángulo con la función cv2.rectangle, Esta función recibe la imagen, las coordenadas para el rectángulo y el color del rectangulo.\n",
    "\n",
    "Por cada rostro detectado, se utiliza el modelo de clasificador *eye_cascade*. A este clasificador se le pasa como parametro la imagen en grises contenida dentro del rectangulo correspondiente al rostro detectado.\n",
    "Esta función regresa coordenadas de los ojos detectados.\n",
    "Posteriormente se dibujan rectangulos alrededor de cada ojo detectado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se utiliza el modelo detector de rostros que ya cargamos anteriormente\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)  #Indicamos los parámetros\n",
    "#faces = face_cascade.detectMultiScale(gray, 1.01, 1)\n",
    "for (x,y,w,h) in faces: #iterando en las coordenadas en donde se detectaron rostros con el modelo\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2) #Se dibujan los rectángulos en donde se encontraron rostros\n",
    "    roi_gray = gray[y:y+h, x:x+w]  #region de interés de la imagen en gris\n",
    "    roi_color = img[y:y+h, x:x+w]  #region de interés de la imagen a color\n",
    "    #Se utiliza el detector de ojos que ya cargamos anteriormente\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes: #Iterando en las coordenadas de los ojos encontrados\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2) #Se dibujan rectángulos en donde se encontraron ojos\n",
    "\n",
    "plt.imshow(img)     \n",
    "plt.show()\n",
    "#cv2.imshow('img',img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:magenta\">__Pruébalo__:</span> Prueba detectar rostros y ojos con las otras tres fotografías que estan en la carpeta. Después, sube tu propia fotografía y prueba si detecta tu rostro y ojos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV incluye más modelos de clasificación para otros objetos. Puedes revisar algunos en esta liga:\n",
    "https://github.com/opencv/opencv/tree/master/data/haarcascades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Porqué se dibuja el rectángulo sobre los ojos si solo se pasa la región de la cara y no la imagen completa?\n",
    "\n",
    "En esta línea\n",
    "cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2) <br>\n",
    "Se pasa como parámetro *roi_color* como la imagen en donde se dibujaran los rectángulos de los ojos. Sin embargo, a pesar que solo representa la región en donde se encontró un rosto, al dibujarse los rectangulos de los ojos si quedan dibujados en los lugares correspondientes. <br>\n",
    "\n",
    "Esto se debe a que cuando se trabaja con arreglos de numpy, y una variable se iguala a un arreglo o a un segmento (slice) de un arreglo, los valores se pasan como referencia y no como copia (por lo que hay que tener cuidado de no encimar valores). <br>\n",
    "A continuación un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se crea un arreglo numpy\n",
    "a = np.array([1, 3, 4, 5, 6 ,7])\n",
    "print(\"Arreglo a original: \", a)\n",
    "#Se crea el arreglo b con un segmento de a\n",
    "b = a[:3]\n",
    "#Se modifica un elemento de b\n",
    "b[0]=9\n",
    "#Como los valores se pasaron como referencia, también se modifica a\n",
    "print(\"Arreglo b: \", b)\n",
    "print(\"Arreglo a modificado: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:magenta\">__Pruébalo__:</span> Utiliza el modelo *haarcascade_lowerbody.xml* para detectar los cuerpos de la imagen *caminando* que está en la carpeta *images*.\n",
    "\n",
    "Recuerda que el modelo está en https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "\n",
    "Puedes darte una idea de como resolverlo aquí: https://answers.opencv.org/question/95834/opencv-31-upper-body-detection-not-working-in-any-example/\n",
    "\n",
    "Revisa este video en donde se aplica este modelo: https://www.youtube.com/watch?v=PnQ1d1PLvVI\n",
    "\n",
    "Obtendrás una imagen como ésta:\n",
    "\n",
    "<img src=\"./images/caminandoDetected.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utiliza el modelo haarcascade_lowerbody.xml para detectar los cuerpos de la imagen caminando que está en la carpeta images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
